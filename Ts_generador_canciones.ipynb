{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWOA04SUzvC"
      },
      "source": [
        "# **Proyecto: Generador de Letras de Taylor Swift con LSTM**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3azJg_xZCs"
      },
      "source": [
        "En este proyecto, exploraremos la emocionante intersección entre la música y la inteligencia artificial para crear un generador de letras de Taylor Swift. Utilizaremos una técnica de aprendizaje profundo conocida como Long Short Term Memory (LSTM) Recurrent Neural Networks.\n",
        "\n",
        "Taylor Swift, una famosa cantante y compositora, es conocida por sus letras emotivas y cautivadoras. Con la ayuda de las LSTM, buscaremos capturar su estilo lírico distintivo y generar nuevas letras que mantengan la esencia de su música.\n",
        "\n",
        "Las LSTM son una variante de las redes neuronales recurrentes diseñadas para modelar secuencias de datos. Con su capacidad para capturar dependencias a largo plazo en las secuencias, las LSTM son ideales para generar letras de canciones coherentes y auténticas.\n",
        "\n",
        "En este proyecto, entrenaremos un modelo LSTM utilizando un corpus de letras de Taylor Swift. Alimentaremos el modelo con estas letras para que aprenda los patrones y estructuras líricas característicos de su música. Una vez entrenado, el modelo será capaz de generar nuevas letras de Taylor Swift de manera automática.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HmuY0Lvkz2yU"
      },
      "source": [
        "Importamos las librerias necesarias y la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJFZojnyvM72"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys \n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, CuDNNLSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAUVR9VXz54K"
      },
      "outputs": [],
      "source": [
        "path=\"/content/drive/MyDrive/taylor_swift_lyrics.csv\"\n",
        "dataset=  pd.read_csv(path, encoding = \"latin1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r5iFOwcsxCQe",
        "outputId": "4e21945d-c312-4722-8735-6fd9a6d6aeef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a410aac3-3487-43f8-9d80-28ac892b5afd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>track_title</th>\n",
              "      <th>track_n</th>\n",
              "      <th>lyric</th>\n",
              "      <th>line</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>He said the way my blue eyes shined</td>\n",
              "      <td>1</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>Put those Georgia stars to shame that night</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>I said, \"That's a lie\"</td>\n",
              "      <td>3</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>Just a boy in a Chevy truck</td>\n",
              "      <td>4</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Taylor Swift</td>\n",
              "      <td>Tim McGraw</td>\n",
              "      <td>1</td>\n",
              "      <td>That had a tendency of gettin' stuck</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a410aac3-3487-43f8-9d80-28ac892b5afd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a410aac3-3487-43f8-9d80-28ac892b5afd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a410aac3-3487-43f8-9d80-28ac892b5afd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         artist         album track_title  track_n  \\\n",
              "0  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
              "1  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
              "2  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
              "3  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
              "4  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
              "\n",
              "                                         lyric  line  year  \n",
              "0          He said the way my blue eyes shined     1  2006  \n",
              "1  Put those Georgia stars to shame that night     2  2006  \n",
              "2                       I said, \"That's a lie\"     3  2006  \n",
              "3                  Just a boy in a Chevy truck     4  2006  \n",
              "4         That had a tendency of gettin' stuck     5  2006  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LXgGKyXVxOtN",
        "outputId": "2e072587-89ed-401c-fbfa-c98a3afdfca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b5281b6-df9f-4bc2-bdd1-aadf7791c345\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_n</th>\n",
              "      <th>line</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4862.000000</td>\n",
              "      <td>4862.000000</td>\n",
              "      <td>4862.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.216989</td>\n",
              "      <td>28.426573</td>\n",
              "      <td>2011.882764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.696379</td>\n",
              "      <td>18.343649</td>\n",
              "      <td>3.571447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2012.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b5281b6-df9f-4bc2-bdd1-aadf7791c345')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b5281b6-df9f-4bc2-bdd1-aadf7791c345 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b5281b6-df9f-4bc2-bdd1-aadf7791c345');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           track_n         line         year\n",
              "count  4862.000000  4862.000000  4862.000000\n",
              "mean      8.216989    28.426573  2011.882764\n",
              "std       4.696379    18.343649     3.571447\n",
              "min       1.000000     1.000000  2006.000000\n",
              "25%       4.000000    13.000000  2010.000000\n",
              "50%       8.000000    26.000000  2012.000000\n",
              "75%      12.000000    41.000000  2014.000000\n",
              "max      19.000000   101.000000  2017.000000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UwWixZhhzt9W"
      },
      "source": [
        "Ahora concatenamos las líneas de cada canción para obtener cada canción por separado en una cadena."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DFbVyycoFek"
      },
      "outputs": [],
      "source": [
        "def processFirstLine(lyrics, songID, songName, row):\n",
        "    lyrics.append(row['lyric'] + '\\n')\n",
        "    songID.append( row['year']*100+ row['track_n'])\n",
        "    songName.append(row['track_title'])\n",
        "    return lyrics,songID,songName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TNW-SFTz-cZ"
      },
      "outputs": [],
      "source": [
        "# Definir listas vacías para las letras, el ID de la canción y el nombre de la canción \n",
        "lyrics = []\n",
        "songID = []\n",
        "songName = []\n",
        "\n",
        "# songNumber indica el número de la canción en el conjunto de datos\n",
        "songNumber = 1\n",
        "\n",
        "# i indica el número de la canción\n",
        "i = 0\n",
        "isFirstLine = True\n",
        "\n",
        "# Iterar a través de cada línea de letras y unirlas para cada canción de manera independiente \n",
        "for index,row in dataset.iterrows():\n",
        "    if(songNumber == row['track_n']):\n",
        "        if (isFirstLine):\n",
        "            lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "            isFirstLine = False\n",
        "        else :\n",
        "            #si estamos en la misma canción, se unen las lineas de las canciones    \n",
        "            lyrics[i] +=  row['lyric'] + '\\n'\n",
        "    #si ya estan todas las partes de la canción seguir con la otra:    \n",
        "    else :\n",
        "        lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "        songNumber = row['track_n']\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lEEwMvhpZ_2"
      },
      "outputs": [],
      "source": [
        "# Definimos un nuevo marco de datos de pandas para guardar el ID de la canción, el nombre de la canción y las letras para usarlos más tarde\n",
        "lyrics_data = pd.DataFrame({'songID':songID, 'songName':songName, 'lyrics':lyrics })\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F_xrEC7B1eoM"
      },
      "source": [
        "Guardamos las canciones completas en formato .txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iyWei1j1X5U"
      },
      "outputs": [],
      "source": [
        "with open('lyricsText.txt', 'w',encoding=\"utf-8\") as filehandle:  \n",
        "    for listitem in lyrics:\n",
        "        filehandle.write('%s\\n' % listitem)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hW1bcUs02oVF"
      },
      "source": [
        "## Procesamiento de datos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cm60oA7s2tj0"
      },
      "source": [
        "Convertimos todo el contenido en minúsculas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVOSN8qIqz0P"
      },
      "outputs": [],
      "source": [
        "textFileName = 'lyricsText.txt'\n",
        "raw_text = open(textFileName, encoding = 'UTF-8').read()\n",
        "raw_text = raw_text.lower()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EBkjiffE3ALc"
      },
      "source": [
        "### Mapping"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1tdeDWda3FWc"
      },
      "source": [
        "Creamos dos diccionarios, uno para convertir caracteres a enteros, el otro para convertir enteros de nuevo a caracteres:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNfjF11126eF"
      },
      "outputs": [],
      "source": [
        "#chars a ints :\n",
        "chars = sorted(list(set(raw_text)))\n",
        "int_chars = dict((i, c) for i, c in enumerate(chars))\n",
        "chars_int = dict((i, c) for c, i in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOk9m8rt3Nyt"
      },
      "outputs": [],
      "source": [
        "# número de caracteres y vocabulario en nuestro texto:\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZPJY2bG3WN1",
        "outputId": "015cfa2d-1d7d-4714-cdbd-e7c724107487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Characters :  173698\n",
            "Total Vocab :  58\n"
          ]
        }
      ],
      "source": [
        "print('Total Characters : ' , n_chars) #caracteres en lyricsText.txt\n",
        "print('Total Vocab : ', n_vocab) #caracteres únicos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IsWo39iQ31n8"
      },
      "source": [
        "## Realización de muestras y etiquetas para alimentar la LSTM RNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG_TObvh3sW9",
        "outputId": "65291a3a-b37d-4ed6-acc2-c1fae20e51ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Patterns :  173598\n"
          ]
        }
      ],
      "source": [
        "# process the dataset:\n",
        "seq_len = 100\n",
        "data_X = []\n",
        "data_y = []\n",
        "\n",
        "for i in range(0, n_chars - seq_len, 1):\n",
        "    # Input Sequeance(will be used as samples)\n",
        "    seq_in  = raw_text[i:i+seq_len]\n",
        "    # Output sequence (will be used as target)\n",
        "    seq_out = raw_text[i + seq_len]\n",
        "    # Store samples in data_X\n",
        "    data_X.append([chars_int[char] for char in seq_in])\n",
        "    # Store targets in data_y\n",
        "    data_y.append(chars_int[seq_out])\n",
        "n_patterns = len(data_X)\n",
        "print( 'Total Patterns : ', n_patterns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QznqUs6Z4SN8"
      },
      "source": [
        "Prepararemos las muestras y las etiquetas para que estén listas para entrenar nuestro modelo.\n",
        "* Reformar las muestras\n",
        "* Normalizarlos\n",
        "* Codificar las salidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEblpQMN4FGE"
      },
      "outputs": [],
      "source": [
        "# Remodelar X para ser adecuado para entrar en LSTM RNN:\n",
        "X = np.reshape(data_X , (n_patterns, seq_len, 1))\n",
        "# Normalizamos los datos :\n",
        "X = X/ float(n_vocab)\n",
        "#Codificamos salidas:\n",
        "y = np_utils.to_categorical(data_y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ZFiB554zbU"
      },
      "source": [
        "# Construimos el modelo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hsgWtd5El1"
      },
      "source": [
        "Comenzaremos determinando cuántas capas tendrá nuestro modelo y cuántos nodos tendrá cada capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLkltiG24U0O"
      },
      "outputs": [],
      "source": [
        "LSTM_layer_num = 4 #capas\n",
        "layer_size = [256,256,256,256] #nodos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4YMs9DBi5Mhs"
      },
      "source": [
        "Definimos nuestro modelo secuencial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ6yz_tp5KSd"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3N3-zpGo56S-"
      },
      "source": [
        "Hacemos uso de CuDNNLSTM que es 15 veces más rápido LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23aqGTnF5c3P"
      },
      "outputs": [],
      "source": [
        "model.add(CuDNNLSTM(layer_size[0], input_shape =(X.shape[1], X.shape[2]), return_sequences = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmFIjQwj6EMl"
      },
      "outputs": [],
      "source": [
        "for i in range(1,LSTM_layer_num) :\n",
        "    model.add(CuDNNLSTM(layer_size[i], return_sequences=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7xSHjF_6Jgo"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUDtoC16S98"
      },
      "source": [
        "Agregamos una capa de salida y definimos su función de activación y compilamos el modelo con los parametros de pédida y optimización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLb1uGHD6cbO"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9BPrmM5C61et"
      },
      "source": [
        "Resumimos nuestro nuevo modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeM4KZWv6znO",
        "outputId": "9b497c51-a3e7-4386-f461-a99b7d657845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 100, 256)          265216    \n",
            "                                                                 \n",
            " cu_dnnlstm_1 (CuDNNLSTM)    (None, 100, 256)          526336    \n",
            "                                                                 \n",
            " cu_dnnlstm_2 (CuDNNLSTM)    (None, 100, 256)          526336    \n",
            "                                                                 \n",
            " cu_dnnlstm_3 (CuDNNLSTM)    (None, 100, 256)          526336    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 58)                1484858   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 58)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,329,082\n",
            "Trainable params: 3,329,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fMA5cbC87FFN"
      },
      "source": [
        "Con este output vemos que todos nuestros parámetros son entrenables\n",
        "\n",
        "\n",
        "```\n",
        "Total params: 3,329,082\n",
        "Trainable params: 3,329,082\n",
        "Non-trainable params: 0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sM5C86Ki7iHF"
      },
      "source": [
        "Realizamos un Callback\n",
        "\n",
        "¿Qué es un callback?\n",
        "es una función que se llama después de cierto tiempo.\n",
        "\n",
        "Para este caso se llamará a un punto de control para guardar los resultados del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq-ZWErv6-uV"
      },
      "outputs": [],
      "source": [
        "#Hacemos el punto de control\n",
        "checkpoint_name = 'Weights-LSTM-improvement-{epoch:03d}-{loss:.5f}-bigger.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='loss', verbose = 1, save_best_only = True, mode ='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hf2FApxs8jTt"
      },
      "source": [
        "# Entrenando al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He2vVTgm_Ydt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2255
        },
        "id": "a95hUKQf4OnJ",
        "outputId": "7b7feb5f-f5ed-4e1e-d43c-24aabfa18054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 138878 samples, validate on 34720 samples\n",
            "Epoch 1/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 2.8300 - val_loss: 2.7864\n",
            "\n",
            "Epoch 00001: loss improved from 3.00537 to 2.82996, saving model to Weights-LSTM-improvement-001-2.82996-bigger.hdf5\n",
            "Epoch 2/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 2.6424 - val_loss: 2.6723\n",
            "\n",
            "Epoch 00002: loss improved from 2.82996 to 2.64236, saving model to Weights-LSTM-improvement-002-2.64236-bigger.hdf5\n",
            "Epoch 3/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 2.3721 - val_loss: 2.5978\n",
            "\n",
            "Epoch 00003: loss improved from 2.64236 to 2.37208, saving model to Weights-LSTM-improvement-003-2.37208-bigger.hdf5\n",
            "Epoch 4/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 1.9650 - val_loss: 2.6343\n",
            "\n",
            "Epoch 00004: loss improved from 2.37208 to 1.96500, saving model to Weights-LSTM-improvement-004-1.96500-bigger.hdf5\n",
            "Epoch 5/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 1.5298 - val_loss: 2.6932\n",
            "\n",
            "Epoch 00005: loss improved from 1.96500 to 1.52981, saving model to Weights-LSTM-improvement-005-1.52981-bigger.hdf5\n",
            "Epoch 6/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 1.1555 - val_loss: 2.8772\n",
            "\n",
            "Epoch 00006: loss improved from 1.52981 to 1.15551, saving model to Weights-LSTM-improvement-006-1.15551-bigger.hdf5\n",
            "Epoch 7/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.8443 - val_loss: 3.1771\n",
            "\n",
            "Epoch 00007: loss improved from 1.15551 to 0.84430, saving model to Weights-LSTM-improvement-007-0.84430-bigger.hdf5\n",
            "Epoch 8/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.5888 - val_loss: 3.4821\n",
            "\n",
            "Epoch 00008: loss improved from 0.84430 to 0.58876, saving model to Weights-LSTM-improvement-008-0.58876-bigger.hdf5\n",
            "Epoch 9/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.3961 - val_loss: 3.9257\n",
            "\n",
            "Epoch 00009: loss improved from 0.58876 to 0.39615, saving model to Weights-LSTM-improvement-009-0.39615-bigger.hdf5\n",
            "Epoch 10/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.2646 - val_loss: 4.2018\n",
            "\n",
            "Epoch 00010: loss improved from 0.39615 to 0.26464, saving model to Weights-LSTM-improvement-010-0.26464-bigger.hdf5\n",
            "Epoch 11/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.1873 - val_loss: 4.5327\n",
            "\n",
            "Epoch 00011: loss improved from 0.26464 to 0.18727, saving model to Weights-LSTM-improvement-011-0.18727-bigger.hdf5\n",
            "Epoch 12/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.1476 - val_loss: 4.7776\n",
            "\n",
            "Epoch 00012: loss improved from 0.18727 to 0.14758, saving model to Weights-LSTM-improvement-012-0.14758-bigger.hdf5\n",
            "Epoch 13/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.1292 - val_loss: 4.9543\n",
            "\n",
            "Epoch 00013: loss improved from 0.14758 to 0.12921, saving model to Weights-LSTM-improvement-013-0.12921-bigger.hdf5\n",
            "Epoch 14/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.1188 - val_loss: 5.1165\n",
            "\n",
            "Epoch 00014: loss improved from 0.12921 to 0.11878, saving model to Weights-LSTM-improvement-014-0.11878-bigger.hdf5\n",
            "Epoch 15/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.1109 - val_loss: 5.1407\n",
            "\n",
            "Epoch 00015: loss improved from 0.11878 to 0.11092, saving model to Weights-LSTM-improvement-015-0.11092-bigger.hdf5\n",
            "Epoch 16/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0986 - val_loss: 5.3270\n",
            "\n",
            "Epoch 00016: loss improved from 0.11092 to 0.09858, saving model to Weights-LSTM-improvement-016-0.09858-bigger.hdf5\n",
            "Epoch 17/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0949 - val_loss: 5.5357\n",
            "\n",
            "Epoch 00017: loss improved from 0.09858 to 0.09487, saving model to Weights-LSTM-improvement-017-0.09487-bigger.hdf5\n",
            "Epoch 18/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.0963 - val_loss: 5.4257\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.09487\n",
            "Epoch 19/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.0906 - val_loss: 5.5971\n",
            "\n",
            "Epoch 00019: loss improved from 0.09487 to 0.09062, saving model to Weights-LSTM-improvement-019-0.09062-bigger.hdf5\n",
            "Epoch 20/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0862 - val_loss: 5.8942\n",
            "\n",
            "Epoch 00020: loss improved from 0.09062 to 0.08617, saving model to Weights-LSTM-improvement-020-0.08617-bigger.hdf5\n",
            "Epoch 21/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.0828 - val_loss: 5.8484\n",
            "\n",
            "Epoch 00021: loss improved from 0.08617 to 0.08280, saving model to Weights-LSTM-improvement-021-0.08280-bigger.hdf5\n",
            "Epoch 22/30\n",
            "138878/138878 [==============================] - 186s 1ms/step - loss: 0.0784 - val_loss: 5.8140\n",
            "\n",
            "Epoch 00022: loss improved from 0.08280 to 0.07837, saving model to Weights-LSTM-improvement-022-0.07837-bigger.hdf5\n",
            "Epoch 23/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0779 - val_loss: 5.9245\n",
            "\n",
            "Epoch 00023: loss improved from 0.07837 to 0.07792, saving model to Weights-LSTM-improvement-023-0.07792-bigger.hdf5\n",
            "Epoch 24/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0767 - val_loss: 6.0071\n",
            "\n",
            "Epoch 00024: loss improved from 0.07792 to 0.07667, saving model to Weights-LSTM-improvement-024-0.07667-bigger.hdf5\n",
            "Epoch 25/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0763 - val_loss: 6.0937\n",
            "\n",
            "Epoch 00025: loss improved from 0.07667 to 0.07627, saving model to Weights-LSTM-improvement-025-0.07627-bigger.hdf5\n",
            "Epoch 26/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0759 - val_loss: 6.2694\n",
            "\n",
            "Epoch 00026: loss improved from 0.07627 to 0.07590, saving model to Weights-LSTM-improvement-026-0.07590-bigger.hdf5\n",
            "Epoch 27/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0673 - val_loss: 6.1307\n",
            "\n",
            "Epoch 00027: loss improved from 0.07590 to 0.06726, saving model to Weights-LSTM-improvement-027-0.06726-bigger.hdf5\n",
            "Epoch 28/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0700 - val_loss: 6.1695\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.06726\n",
            "Epoch 29/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0713 - val_loss: 6.2134\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.06726\n",
            "Epoch 30/30\n",
            "138878/138878 [==============================] - 187s 1ms/step - loss: 0.0665 - val_loss: 6.2796\n",
            "\n",
            "Epoch 00030: loss improved from 0.06726 to 0.06650, saving model to Weights-LSTM-improvement-030-0.06650-bigger.hdf5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75e80620f0>"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_params = {'epochs':30,\n",
        "                'batch_size':128,\n",
        "                'callbacks':callbacks_list,\n",
        "                'verbose':1,\n",
        "                'validation_split':0.2,\n",
        "                'validation_data':None,\n",
        "                'shuffle': True,\n",
        "                'initial_epoch':0,\n",
        "                'steps_per_epoch':None,\n",
        "                'validation_steps':None}\n",
        "\n",
        "model.fit(X,\n",
        "          y,\n",
        "          epochs = model_params['epochs'],\n",
        "           batch_size = model_params['batch_size'],\n",
        "           callbacks= model_params['callbacks'],\n",
        "           verbose = model_params['verbose'],\n",
        "           validation_split = model_params['validation_split'],\n",
        "           validation_data = model_params['validation_data'],\n",
        "           shuffle = model_params['shuffle'],\n",
        "           initial_epoch = model_params['initial_epoch'],\n",
        "           steps_per_epoch = model_params['steps_per_epoch'],\n",
        "           validation_steps = model_params['validation_steps'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sud9lOmYguG"
      },
      "outputs": [],
      "source": [
        "# Pesamos la exactitud del modelo :\n",
        "wights_file = './models/Weights-LSTM-improvement-004-2.49538-bigger.hdf5' # weights file path\n",
        "model.load_weights(wights_file)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "I5EngGk8YuJv",
        "outputId": "05d07c6a-c08a-4b16-b3f9-65207a89b43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed : \n",
            "\"  once, i've been waiting, waiting\n",
            "ooh whoa, ooh whoa\n",
            "and all at once, you are the one, i have been w \"\n",
            "\n",
            "eu h mool shoea\n",
            "a eir, bo ly lean on the sast\n",
            "is tigm's the noen uo doy, fo shey stant tas you fot you srart aoo't you tein so my liost\n",
            "i spaye \n",
            "somethppel' cua\n",
            "iy yas tn mu, io' me\n",
            "ohehip in the uorlirs tiines ho a ban't teit dven aester, tee tame\n",
            "mnweiny you'd be pe k bet thing\n",
            "oe eowt the light i\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# set a random seed :\n",
        "start = np.random.randint(0, len(data_X)-1)\n",
        "pattern = data_X[start]\n",
        "print('Seed : ')\n",
        "print(\"\\\"\",''.join([int_chars[value] for value in pattern]), \"\\\"\\n\")\n",
        "\n",
        "# How many characters you want to generate\n",
        "generated_characters = 300\n",
        "\n",
        "# Generate Charachters :\n",
        "for i in range(generated_characters):\n",
        "    x = np.reshape(pattern, ( 1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x,verbose = 0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_chars[index]\n",
        "    #seq_in = [int_chars[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print('\\nDone')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
